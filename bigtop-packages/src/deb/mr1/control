Source: hadoop-0.20-mapreduce
Section: misc
Priority: extra
Maintainer: Todd Lipcon <todd@cloudera.com>
Build-Depends: debhelper (>= 6), ant, ant-optional, liblzo2-dev, python, libz-dev,automake, autoconf (>= 2.61), sharutils, g++ (>= 4), git-core, libfuse-dev
Standards-Version: 3.8.0
Homepage: http://hadoop.apache.org/core/

Package: hadoop-0.20-mapreduce
Architecture: i386 amd64 
Depends: ${shlibs:Depends}, ${misc:Depends}, hadoop, hadoop-hdfs, adduser
Description: A software platform for processing vast amounts of data
 Hadoop is a software platform that lets one easily write and
 run applications that process vast amounts of data.
 .
 Here's what makes Hadoop especially useful:
  * Scalable: Hadoop can reliably store and process petabytes.
  * Economical: It distributes the data and processing across clusters
                of commonly available computers. These clusters can number
                into the thousands of nodes.
  * Efficient: By distributing the data, Hadoop can process it in parallel
               on the nodes where the data is located. This makes it
               extremely rapid.
  * Reliable: Hadoop automatically maintains multiple copies of data and
              automatically redeploys computing tasks based on failures.
 .
 Hadoop implements MapReduce, using the Hadoop Distributed File System (HDFS).
 MapReduce divides applications into many small blocks of work. HDFS creates
 multiple replicas of data blocks for reliability, placing them on compute
 nodes around the cluster. MapReduce can then process the data where it is
 located.

Package: hadoop-0.20-mapreduce-tasktracker
Architecture: all
Depends: hadoop-0.20-mapreduce (= ${source:Version})
Replaces: hadoop-0.20-mapreduce (<< 0.20.2+737-1)
Breaks: hadoop-0.20-mapreduce (<< 0.20.2+737-1)
Description: Task Tracker for Hadoop
 The Task Tracker is the Hadoop service that accepts MapReduce tasks and
 computes results. Each node in a Hadoop cluster that should be doing
 computation should run a Task Tracker.

Package: hadoop-0.20-mapreduce-jobtracker
Architecture: all
Depends: hadoop-0.20-mapreduce (= ${source:Version})
Replaces: hadoop-0.20-mapreduce (<< 0.20.2+737-1)
Breaks: hadoop-0.20-mapreduce (<< 0.20.2+737-1), hadoop-0.20-mapreduce-jobtrackerha
Description: JobTracker for Hadoop
 The jobtracker is a central service which is responsible for managing
 the tasktracker services running on all nodes in a Hadoop Cluster.
 The jobtracker allocates work to the tasktracker nearest to the data
 with an available work slot.

Package: hadoop-0.20-conf-pseudo
Provides: hadoop-0.20-conf-pseudo
Architecture: all
Depends: hadoop, hadoop-hdfs-namenode, hadoop-hdfs-datanode, hadoop-hdfs-secondarynamenode, hadoop-0.20-mapreduce-jobtracker (= ${source:Version}), hadoop-0.20-mapreduce-tasktracker (= ${source:Version})
Breaks: hadoop-conf-pseudo
Description: Hadoop installation in pseudo-distributed mode with MRv1
 Installation of this RPM will setup your machine to run in pseudo-distributed mode
 where each Hadoop daemon runs in a separate Java process. You will be getting old
 style daemons (MRv1) for Hadoop jobtracker and Hadoop tasktracker instead of new
 YARN (MRv2) ones.

Package: hadoop-0.20-mapreduce-jobtrackerha
Provides: hadoop-0.20-mapreduce-jobtrackerha
Architecture: all
Depends: hadoop-0.20-mapreduce (= ${source:Version})
Breaks: hadoop-0.20-mapreduce-jobtracker, hadoop-0.20-jobtracker
Description: High Availability JobTracker for Hadoop
 The Hadoop MapReduce JobTracker High Availability Daemon provides a 
 High Availability JobTracker. JobTracker (installed by 
 hadoop-0.20-mapreduce-jobtracker) and JobTracker High Availability 
 (installed by this package - hadoop-0.20-mapreduce-jobtrackerha)
 can not be installed together on the same machine. Only one of them should
 be installed on a given machine at any given time. When used in coordination
 with Hadoop MapReduce failover controller (installed by
 hadoop-0.20-mapreduce-zkfc), this JobTracker provides automatic failover.
 The jobtracker is a central service which is responsible for managing
 the tasktracker services running on all nodes in a Hadoop Cluster.
 The jobtracker allocates work to the tasktracker nearest to the data
 with an available work slot.

Package: hadoop-0.20-mapreduce-zkfc
Provides: hadoop-0.20-mapreduce-zkfc
Architecture: all
Depends: hadoop-0.20-mapreduce-jobtrackerha (= ${source:Version}), zookeeper (>= 3.4.0)
Description: Hadoop MapReduce failover controller
 The Hadoop MapReduce failover controller is a Zookeeper client which also
 manages the state of the JobTracker. Any machines running ZKFC also need to
 run High Availability JobTracker (installed by hadoop-0.20-mapreduce-jobtrackerha).
 The ZKFC is responsible for: Health monitoring, Zookeeper
 session management and Zookeeper-based election.
