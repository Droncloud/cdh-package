#!/bin/bash
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -ex

[ -f cdh-parcel.props ] && . cdh-parcel.props

PKG_ARCHIVE=${PKG_ARCHIVE:-"http://repos.jenkins.cloudera.com/cdh5.0.0b1-nightly/"}
CDH_VERSION=${CDH_VERSION:-"5.0.0"}

# If PKG_FORMAT not specified assume tarballs
if [ -z "$PKG_FORMAT" ] ; then
  rm -rf build
  mkdir build
  cat > build/cdh-parcel.props <<__EOT__
PKG_ARCHIVE="$PKG_ARCHIVE"
CDH_VERSION="$CDH_VERSION"
__EOT__
  tar -C build -czf build/cdh-parcel-${FULL_VERSION}.tar.gz cdh-parcel.props
  exit 0
fi

REDHAT_RELEASES="rhel|redhat|centos|red.hat"
SUSE_RELEASES="suse|sles"
UBUNTU_RELEASES="lucid|maverick|precise"
ARC="`uname -m`"

if [ "$ARC" = "x86_64" ] ; then
  DEB_ARC="amd64"
else
  DEB_ARC="i386"
fi

# The following block is quite messy, since it has
# to account for different URL schemas for different
# types of repos
if egrep -i $UBUNTU_RELEASES /etc/*release ;then
  for release in `echo $UBUNTU_RELEASES | tr '|' ' '` ; do
    if fgrep -q $release /etc/*release ; then
      PKGS="`curl ${PKG_ARCHIVE}/ubuntu/${release}/${DEB_ARC}/cdh/dists/${release}-cdh${CDH_VERSION}/contrib/binary-${DEB_ARC}/Packages 2>/dev/null | \
             sed -ne '/^Filename:/s#^Filename: #'"${PKG_ARCHIVE}/ubuntu/${release}/${DEB_ARC}/cdh/"'#p'`"
    fi
  done
elif [ -f /etc/debian_version ] ;then
  release=squeeze
  PKGS="`curl ${PKG_ARCHIVE}/debian/${release}/${DEB_ARC}/cdh/dists/${release}-cdh${CDH_VERSION}/contrib/binary-${DEB_ARC}/Packages 2>/dev/null | \
         sed -ne '/^Filename:/s#^Filename: #'"${PKG_ARCHIVE}/debian/${release}/${DEB_ARC}/cdh/"'#p'`"
elif egrep -i $REDHAT_RELEASES /etc/*release ;then
  if fgrep "6." /etc/*release ;then
    PKGS="${PKG_ARCHIVE}/redhat/6/${ARC}/cdh/${CDH_VERSION}/RPMS"
  else
    PKGS="${PKG_ARCHIVE}/redhat/5/${ARC}/cdh/${CDH_VERSION}/RPMS"
  fi
elif egrep -i $SUSE_RELEASES /etc/*release ;then
  PKGS="${PKG_ARCHIVE}/sles/11/${ARC}/cdh/${CDH_VERSION}/RPMS/"
else
  echo "Looks like we don't support the following OS:"
  cat /etc/*release
  exit 1
fi

# Download the packages
rm -rf dl
mkdir dl
(cd dl ; wget -N -r -l2 --no-parent $PKGS)

# Make sure we filter out the most recent versions of the packages
#RPMS=`find dl -name \*.rpm -printf '%p\t'  -exec rpm -q --qf '%{NAME}\n' -p {} \; 2>/dev/null`
#DEBS=`find dl -name \*.deb -printf '%p\t'  -exec bash -c 'dpkg -I {} | grep Package: | cut -f3 -d\  ' \; 2>/dev/null` 

# Unpack the bits
rm -rf build
mkdir -p build/seen

# Create metadata directory
mkdir -p build/meta

# We don't want to recurse into ourselves 
rm -rf `find dl -type f -name cdh-parcel\*`

(
echo "{"
JSON_IS_STUPID=""
for pkg in $(ls -t `find dl -type f`) ; do
  case $pkg in
     *.deb) PKG_NAME=`dpkg -I $pkg | grep Package: | awk '{ print $2 }'`
            if [ ! -f build/seen/$PKG_NAME ] ; then
              PKG_VERSION=`dpkg -I $pkg | grep Version: | awk '{ print $2 }'`
              dpkg -x $pkg ./build
              echo $PKG_VERSION > build/seen/${PKG_NAME}
              echo "  ${JSON_IS_STUPID} \"$PKG_NAME\" : {"
              echo "    \"name\": \"$PKG_NAME\","
              echo "    \"version\": \"$PKG_VERSION\","
              echo "    \"files\" : {"
              dpkg-deb -c $pkg | awk '{ print "\"" $6 "\" : {}" }' | sed -e 's/$/,/'
              echo "    }"
              echo "  }"
              JSON_IS_STUPID=","
            fi
            ;;
     *.rpm) PKG_NAME=`rpm -q --qf '%{NAME}' -p $pkg`
            if [ ! -f build/seen/$PKG_NAME ] ; then
              PKG_VERSION=`rpm -q --qf '%{VERSION}' -p $pkg`
              rpm2cpio $pkg | (cd build ; cpio -i --make-directories)
              echo $PKG_VERSION > build/seen/$PKG_NAME
              echo "  ${JSON_IS_STUPID} \"$PKG_NAME\" : {"
              echo "    \"name\": \"$PKG_NAME\","
              echo "    \"version\": \"$PKG_VERSION\","
              echo "    \"files\" : {"
              rpm -qpl $pkg | awk '{ print "\"" $1 "\" : {}" }' | sed -e 's/$/,/'
              echo "    }"
              echo "  }"
              JSON_IS_STUPID=","
            fi
            ;;
  esac
  rm $pkg
done
echo "}"
) > build/meta/filelist.json
# Rewrite paths to be relative to parcel root (RPMs)
perl -pi -e 's#^"/etc/#      "etc/#' build/meta/filelist.json
perl -pi -e 's#^"/usr/#      "#' build/meta/filelist.json
perl -0pi -e 's#"/var/.*\n##g' build/meta/filelist.json
# Rewrite paths to be relative to parcel root (debs)
perl -0pi -e 's#"\./" : {},\n##g' build/meta/filelist.json
perl -0pi -e 's#"\./usr/" : {},\n##g' build/meta/filelist.json
perl -pi -e 's#^"\./etc/#      "etc/#' build/meta/filelist.json
perl -pi -e 's#^"\./usr/#      "#' build/meta/filelist.json
perl -0pi -e 's#"\./var/.*\n##g' build/meta/filelist.json
# Handle empty rpms
perl -pi -e 's/\(contains no files\)//' build/meta/filelist.json
# Remove trailing commas
perl -0pi -e's/,\n\    }/\n\    }/g' build/meta/filelist.json

# Fix the symlinks
for link in `find build/usr/lib/ -type l` ; do
  target=`readlink $link`
  TOPDIR=`echo $link | sed -e 's#^build/usr/lib/##' -e 's#[^/]\+#..#g'`
  case $target in
    /usr/lib/*)
                rm -f $link
                ln -s $TOPDIR/lib/`echo $target |sed -e 's#/usr/lib/##'` $link
                ;;
    /usr/share/*)
                rm -f $link
                ln -s $TOPDIR/share/`echo $target |sed -e 's#/usr/share##'` $link
  esac
done

# Links to python libs under virtualenv in Hue have to absolute.
# This code only applies to debian since these links are relative
# only in Hue's debian package
for link in `find build/usr/lib/hue/build/env/lib/python* -type l`; do
  target=`readlink $link`
  rm -f $link
  ln -s `echo $target | sed -e 's#\(\.\./\)\(\.\./\)*#/usr/#'` $link
done

# Set up post install symlink for impala/sbin to point to impala/sbin-retail
# In other words, use retail binary by default.
ln -s sbin-retail build/usr/lib/impala/sbin

# FIXME: special handling for Hue
HUE_APPS=`ls build/usr/lib/hue/apps | grep -v Makefile | xargs`

# Removing the broken symlinks to the mutable files
rm -f build/usr/lib/hue/desktop/desktop.db
rm -f build/usr/lib/hue/app.reg
rm -f build/usr/lib/hue/build/env/lib/python*/site-packages/hue.pth

rm -f build/usr/lib/hue/desktop/conf
rm -f build/usr/lib/hue/desktop/logs
mkdir build/usr/lib/hue/desktop/logs
cp -r build/etc/hue build/usr/lib/hue/desktop/conf
pushd build/usr/lib/hue
 /bin/bash -x ./tools/relocatable.sh
 for app in $HUE_APPS ; do
   ROOT=`pwd` HUE_APP_REG_DIR=. HUE_PTH_DIR=`ls -d build/env/lib/python*/site-packages/` DESKTOP_DB_CONFIG=django.db.backends.sqlite3:desktop/desktop.db \
         DESKTOP_LOGLEVEL=WARN DESKTOP_LOG_DIR=/tmp ./build/env/bin/python ./tools/app_reg/app_reg.py --install `pwd`/apps/$app
 done
 /bin/bash -x ./tools/relocatable.sh
 find . -name '*.py[oc]' -exec rm -f {} \;
 sed -i -e '/"path"/s#:.*".*lib/hue#: ".#g' app.reg
popd

# Figure out the location of bigtop-utils
if [ -d build/usr/lib/bigtop-utils ] ; then
  BIGTOP_UTILS_HOME=lib/bigtop-utils
else
  BIGTOP_UTILS_HOME=libexec/bigtop-utils
fi

DISTRO_LESS_FULL_VERSION=`echo $CDH_PARCEL_CUSTOM_VERSION | sed -e 's#\.[^\.]*$##'`
DASH_SEPARATED_CUSTOM_VERSION=`echo $CDH_PARCEL_CUSTOM_VERSION | sed -e 's/\.\([^\.]*\)$/-\1/'`

# Create a bunch of metadata
(cat <<__EOT__
{
  "name":               "CDH",
  "version":            "$DISTRO_LESS_FULL_VERSION",
  "extraVersionInfo": {
    "fullVersion":        "$DASH_SEPARATED_CUSTOM_VERSION",
    "baseVersion":        "$CDH_PARCEL_BASE_VERSION",
    "patchCount":         "$CDH_CUSTOMER_PATCH"
  },
  "minPrevVersion":     "$CDH_MIN_PREV_VERSION",
  "maxPrevVersion":     "$CDH_MAX_PREV_VERSION",

  "setActiveSymlink":   true,

  "scripts": {
    "defines": "cdh_env.sh",
    "alternatives": "cdh_alternatives.sh"
  },

  "packages": [
__EOT__

JSON_IS_STUPID=""
for pkg in build/seen/* ; do
  cat <<__EOT__
    ${JSON_IS_STUPID}{ "name":    "`basename $pkg`",
      "version": "`cat $pkg`"
    }
__EOT__
  JSON_IS_STUPID=","
done

cat <<__EOT__
  ],

  "components": [
__EOT__

JSON_IS_STUPID=""
for comp in build/usr/lib/*/cloudera/cdh_version.properties; do
  cat <<__EOT__
    ${JSON_IS_STUPID}{ "name":     "`sed -ne 's/^cloudera.pkg.name=//p' $comp`",
      "version":  "`sed -ne 's/^version=//p' $comp`",
      "pkg_version":  "`sed -ne 's/^cloudera.pkg.version=//p' $comp`" 
    }
__EOT__
  JSON_IS_STUPID=","
done

cat <<__EOT__
  ],

  "provides": [
    "cdh",
    "impala",
    "solr",
    "flume-plugin",
    "hbase-plugin",
    "hue-plugin"
  ],

  "users": {
     "flume": {
       "longname"    : "Flume",
       "home"        : "/var/lib/flume-ng",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "httpfs": {
       "longname"    : "Hadoop HTTPFS",
       "home"        : "/var/run/hadoop-httpfs",
       "shell"       : "/bin/bash",
       "extra_groups": [ ]
     },
     "hdfs": {
       "longname"    : "Hadoop HDFS",
       "home"        : "/var/lib/hadoop-hdfs",
       "shell"       : "/bin/bash",
       "extra_groups": [ "hadoop" ]
     },
     "yarn": {
       "longname"    : "Hadoop Yarn",
       "home"        : "/var/lib/hadoop-yarn",
       "shell"       : "/bin/bash",
       "extra_groups": [ "hadoop" ]
     },
     "mapred": {
       "longname"    : "Hadoop MapReduce",
       "home"        : "/var/lib/hadoop-mapreduce",
       "shell"       : "/bin/bash",
       "extra_groups": [ "hadoop" ]
     },
     "hbase": {
       "longname"    : "HBase",
       "home"        : "/var/run/hbase",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "hive": {
       "longname"    : "Hive",
       "home"        : "/var/lib/hive",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "hue": {
       "longname"    : "Hue",
       "home"        : "/usr/lib/hue",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "oozie": {
       "longname"    : "Oozie User",
       "home"        : "/var/lib/oozie",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "sqoop": {
       "longname"    : "Sqoop",
       "home"        : "/var/lib/sqoop",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "zookeeper": {
       "longname"    : "ZooKeeper",
       "home"        : "/var/run/zookeeper",
       "shell"       : "/bin/false",
       "extra_groups": [ ]
     },
     "sqoop2": {
       "longname"    : "Sqoop 2 User",
       "home"        : "/var/run/sqoop2",
       "shell"       : "/sbin/nologin",
       "extra_groups": [ "sqoop" ]
     },
     "llama": {
       "longname"    : "Llama",
       "home"        : "/var/run/llama",
       "shell"       : "/bin/bash",
       "extra_groups": [ "llama" ]
     },
     "impala": {
       "longname"    : "Impala",
       "home"        : "/var/run/impala",
       "shell"       : "/bin/bash",
       "extra_groups": [ "hive", "hdfs" ]
     },
     "solr": {
       "longname"    : "Solr",
       "home"        : "/var/run/solr",
       "shell"       : "/sbin/nologin",
       "extra_groups": [ ]
     }
  },

  "groups": [
     "hadoop"
  ]
}
__EOT__
) > build/meta/parcel.json

# Now take care of permissions
cat > build/meta/permissions.json <<__EOT__
{
  "lib/hadoop-0.20-mapreduce/sbin/Linux/task-controller": {
    "user":  "root",
    "group": "mapred",
    "permissions": "4754"
  },
  "lib/hadoop-yarn/bin/container-executor": {
    "user":  "root",
    "group": "yarn",
    "permissions": "6050"
  },
  "lib/hue/desktop": {
    "user":  "hue",
    "group": "hue",
    "permissions": "0755"
  },
  "lib/hue/desktop/desktop.db": {
    "user":  "hue",
    "group": "hue",
    "permissions": "0644"
  }
}
__EOT__

# cdh_env.sh
(echo "#!/bin/bash"
#cat build/etc/default/* | grep -v '^[ 	]*#' |\
#                          grep -v '^[ 	]*$' |\
#                          grep -v '_HOME='   |\
#                          grep -v '/etc'     | sort -u
#echo
cat <<__EOT__
CDH_DIRNAME=\${PARCEL_DIRNAME:-"CDH-$DISTRO_LESS_FULL_VERSION"}
export CDH_HADOOP_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop
export CDH_MR1_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop-0.20-mapreduce
export CDH_HDFS_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop-hdfs
export CDH_HTTPFS_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop-httpfs
export CDH_MR2_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop-mapreduce
export CDH_YARN_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop-yarn
export CDH_HBASE_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hbase
export CDH_ZOOKEEPER_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/zookeeper
export CDH_HIVE_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hive
export CDH_HUE_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hue
export CDH_OOZIE_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/oozie
export CDH_HUE_PLUGINS_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hadoop
export CDH_FLUME_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/flume-ng
export CDH_PIG_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/pig
export CDH_HCAT_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hive-hcatalog
export CDH_SQOOP2_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/sqoop2
export CDH_LLAMA_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/llama
export CDH_LLAMA_NODE_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/llama/nodemanagerlib
export TOMCAT_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/bigtop-tomcat
export JSVC_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/$BIGTOP_UTILS_HOME
export CDH_HADOOP_BIN=\$CDH_HADOOP_HOME/bin/hadoop
export HIVE_DEFAULT_XML=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hive/conf/hive-default.xml
export CDH_IMPALA_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/impala
export CDH_SOLR_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/solr
export CDH_HBASE_INDEXER_HOME=\$PARCELS_ROOT/\$CDH_DIRNAME/lib/hbase-solr
__EOT__
) > build/meta/cdh_env.sh

# cdh_alternatives.sh
BINARIES="beeline flume-ng hadoop hadoop-0.20 hadoop-fuse-dfs hbase hbase-indexer \
          hcat hdfs hive hiveserver2 impala-shell llama mahout mapred oozie pig \
          solrctl sqoop sqoop-codegen sqoop-create-hive-table \
          sqoop-eval sqoop-export sqoop-help sqoop-import sqoop-import-all-tables \
          sqoop-job sqoop-list-databases sqoop-list-tables sqoop-merge sqoop-metastore \
          sqoop-version sqoop2 whirr yarn zookeeper-client \
          zookeeper-server zookeeper-server-cleanup zookeeper-server-initialize"

CONFDIRS="hbase hbase-solr hive hive-hcatalog hive-webhcat impala llama mahout oozie pig solr sqoop sqoop2 zookeeper"
# Some services are 'special' and use conf.empty instead of conf.dist
EMPTY_CONFDIRS="flume-ng hadoop hadoop-httpfs hue"

cat > build/meta/cdh_alternatives.sh <<__EOT__
#!/bin/bash
PRIORITY=10
CDH_DIRNAME=\${PARCEL_DIRNAME:-"CDH-$DISTRO_LESS_FULL_VERSION"}

__EOT__

if egrep -i $SUSE_RELEASES /etc/*release; then
cat >> build/meta/cdh_alternatives.sh <<__EOT__
function safe_deregister_bin {
  BINARY=\$1
  # If the binary doesn't exist, simply deregister it, since we need to keep alternatives DB in sync
  if [ ! -e /usr/bin/\$BINARY ]; then
    update-alternatives --remove \$BINARY \$PARCELS_ROOT/\$CDH_DIRNAME/bin/\$BINARY
  # If the binary is a symlink pointing to alternatives, then we will just let alternatives manage the removal
  elif [ -L /usr/bin/\$BINARY ] && [ "\$(readlink /usr/bin/\$BINARY)" = "/etc/alternatives/\$BINARY" ]; then
    update-alternatives --remove \$BINARY \$PARCELS_ROOT/\$CDH_DIRNAME/bin/\$BINARY
    # Otherwise, we have to defensively remove it
  else
    # Make a copy of the binary if it's not managed by alternatives
    cp /usr/bin/\$BINARY /usr/bin/\${BINARY}~
    # Then deregister the alternative, which on SLES may remove the physical file
    update-alternatives --remove \$BINARY \$PARCELS_ROOT/\$CDH_DIRNAME/bin/\$BINARY
    # If the file was in fact removed during the de-registration process, restore it
    if [ ! -e /usr/bin/\$BINARY ]; then
      mv /usr/bin/\${BINARY}~ /usr/bin/\$BINARY
    fi
    # In all cases, forcefully remove the backup
    rm -f /usr/bin/\${BINARY}~
  fi
}

__EOT__
fi
cat >> build/meta/cdh_alternatives.sh <<__EOT__

if [[ "\$1" == "activate" ]]; then
__EOT__

for BINARY in $BINARIES; do
  echo \
    "  update-alternatives --install /usr/bin/$BINARY $BINARY \$PARCELS_ROOT/\$CDH_DIRNAME/bin/$BINARY \$PRIORITY" \
    >> build/meta/cdh_alternatives.sh
done

for CONFDIR in $CONFDIRS; do
  echo "  mkdir -p /etc/$CONFDIR" >> build/meta/cdh_alternatives.sh
  echo \
    "  update-alternatives --install /etc/$CONFDIR/conf $CONFDIR-conf \$PARCELS_ROOT/\$CDH_DIRNAME/etc/$CONFDIR/conf.dist \$PRIORITY" \
    >> build/meta/cdh_alternatives.sh
done

for CONFDIR in $EMPTY_CONFDIRS; do
  echo "  mkdir -p /etc/$CONFDIR" >> build/meta/cdh_alternatives.sh
  echo \
    "  update-alternatives --install /etc/$CONFDIR/conf $CONFDIR-conf \$PARCELS_ROOT/\$CDH_DIRNAME/etc/$CONFDIR/conf.empty \$PRIORITY" \
    >> build/meta/cdh_alternatives.sh
done

cat >> build/meta/cdh_alternatives.sh <<__EOT__

elif [[ "\$1" == "deactivate" ]]; then

__EOT__

for BINARY in $BINARIES; do
  if egrep -i $SUSE_RELEASES /etc/*release; then
  echo \
    "  safe_deregister_bin \"$BINARY\"" >> build/meta/cdh_alternatives.sh
  else
    echo \
      "  update-alternatives --remove $BINARY \$PARCELS_ROOT/\$CDH_DIRNAME/bin/$BINARY" \
      >> build/meta/cdh_alternatives.sh
  fi
done

for CONFDIR in $CONFDIRS; do
  echo \
    "  update-alternatives --remove $CONFDIR-conf \$PARCELS_ROOT/\$CDH_DIRNAME/etc/$CONFDIR/conf.dist" \
    >> build/meta/cdh_alternatives.sh
  echo "  rmdir --ignore-fail-on-non-empty /etc/$CONFDIR" >> build/meta/cdh_alternatives.sh
done

for CONFDIR in $EMPTY_CONFDIRS; do
  echo \
    "  update-alternatives --remove $CONFDIR-conf \$PARCELS_ROOT/\$CDH_DIRNAME/etc/$CONFDIR/conf.empty" \
    >> build/meta/cdh_alternatives.sh
  echo "  rmdir --ignore-fail-on-non-empty /etc/$CONFDIR" >> build/meta/cdh_alternatives.sh
done

cat >> build/meta/cdh_alternatives.sh <<__EOT__

fi

__EOT__
chmod +x build/meta/cdh_alternatives.sh

# HCatalog also looks for certain environment variables.
HCATALOG_SCRIPTS="hcat"
for file in $HCATALOG_SCRIPTS; do
  sed -i '1a \
  export HADOOP_HOME=$LIB_DIR/hadoop \
  export HCAT_HOME=$LIB_DIR/hive-hcatalog \
  export HIVE_HOME=$LIB_DIR/hive' build/usr/bin/$file
done

# And Pig - if you want pig to work with hcatalog
# I was tempted to just put hcat and pig in the same bucket
# but I don't want to set HADOOP_HOME when it can work it out
# itself. Bad habits, etc.
PIG_SCRIPTS="pig"
for file in $PIG_SCRIPTS; do
  sed -i '1a \
  export HCAT_HOME=$LIB_DIR/hive-hcatalog \
  export HIVE_HOME=$LIB_DIR/hive' build/usr/bin/$file
done

# Magically manipulate the bin scripts to point to ../lib instead of /usr/lib
# Ideally we would want alternatives configuration for bin scripts as well
for file in build/usr/bin/*; do
  # Insert a command that sets the LIB_DIR we want to use
  sed -i '1a \
  # Reference: http://stackoverflow.com/questions/59895/can-a-bash-script-tell-what-directory-its-stored-in\
  SOURCE="${BASH_SOURCE[0]}"\
  BIN_DIR="$( dirname "$SOURCE" )"\
  while [ -h "$SOURCE" ]\
  do\
    SOURCE="$(readlink "$SOURCE")"\
    [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"\
    BIN_DIR="$( cd -P "$( dirname "$SOURCE"  )" && pwd )"\
  done\
  BIN_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"\
  LIB_DIR=$BIN_DIR/../lib' $file
  # Replace /usr/libexec with the libexec dir from within the parcel
  # Replace /usr/lib with the LIB_DIR variable we set in the above line
  # Replace all instances of /etc/default to relatively point to <parcel root>/etc/default
  # Replace default shell in shell scripts to be explicitly bash (since default shell in debian/ubuntu shell is dash)
  sed -i -e 's:/usr/libexec/:\$BIN_DIR/../libexec/:' \
  -e 's:/usr/lib/:\$LIB_DIR/:' \
  -e 's:/etc/default:$BIN_DIR/../etc/default:' \
  -e 's:#!/bin/sh:#!/bin/bash:' $file
done

# Fixing up /usr/lib/hadoop/libexec/hadoop-layout.sh
# The above directly refers to directories in /usr/lib, etc. which don't exist in the CM/parcel use case.

FILE=build/usr/lib/hadoop/libexec/hadoop-layout.sh
# Insert stuff after the first line that doesn't start with a comment
sed -i '1,/^[^#]/ {/^[^#]/i\
\
this="${BASH_SOURCE-$0}"\
common_bin=$(cd -P -- "$(dirname -- "$this")" && pwd -P)\
script="$(basename -- "$this")"\
this="$common_bin/$script"\

}' $FILE
# Replace references to /usr/lib with the relative path to within the parcel
sed -i 's#/usr/lib/#\$common_bin/../../#' $FILE

# Updating catalina.properties in oozie and sqoop2 to not point to /usr/lib/hadoop absolute paths but relatively to hadoop location within the parcel
TOMCAT_SERVERS="oozie/oozie-server oozie/oozie-server-0.20 sqoop2/sqoop-server sqoop2/sqoop-server-0.20"
for server in $TOMCAT_SERVERS; do
  file=build/usr/lib/$server/conf/catalina.properties
  if [ -e $file ];
  then
    sed -i -e '/common.loader=/ s:/usr/lib/:${catalina.base}/../../:g' $file
  fi
done

chmod 555         build/usr/lib/hadoop-yarn/bin/container-executor
chmod 555         build/usr/lib/hadoop-0.20-mapreduce/sbin/*/task-controller
